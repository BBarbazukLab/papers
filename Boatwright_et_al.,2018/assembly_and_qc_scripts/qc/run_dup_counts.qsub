#!/bin/bash
#PBS -M ammorse@ufl.edu
#PBS -N dupcounts
#PBS -m n
#PBS -r n
#PBS -j oe
#PBS -o /scratch/lfs/mcintyre/trago/scripts/PBS_LOGS
#PBS -l walltime=2:00:00
#PBS -l nodes=1:ppn=1
#PBS -l pmem=20gb
#PBS -t 2-37


# Load modules

module load python/2.7.3

#Set directories
PROJ=/scratch/lfs/mcintyre/trago
ORIG=/scratch/lfs/mcintyre/trago/original_data/trago-tetraploids
QC=/scratch/lfs/mcintyre/trago/qc_test
MCPYTHON=/scratch/lfs/mcintyre/python.git

OUTPUT=$QC/fastq_split_dups
if [ ! -e $OUTPUT ]; then mkdir -p $OUTPUT; fi

OUTCOUNTS=$QC/duplicate_counts
if [ ! -e $OUTCOUNTS ]; then mkdir -p $OUTCOUNTS; fi

OUTLOGS=$QC/duplicate_counts/logs
if [ ! -e $OUTLOGS ]; then mkdir -p $OUTLOGS; fi

## Design file (for paired end reads)
     DESIGN_FILE=$PROJ/design_files/qc_design_file.csv

     DESIGN=$(cat $DESIGN_FILE | head -n $PBS_ARRAYID | tail -n 1)
     IFS=',' read -ra ARRAY <<< "$DESIGN"

     READ=${ARRAY[0]}
     NAME=${ARRAY[1]}




$MCPYTHON/fastqSplitDups.py -r1 $ORIG/${READ} --outdir $OUTPUT -o $OUTCOUNTS/${NAME}_duplicate_counts_summary.csv -t $OUTCOUNTS/${NAME}_001_duplicate_sequences.tsv -g $OUTLOGS/${NAME}_001_fastqSplitDups.log
